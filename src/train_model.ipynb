{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c56c23a",
   "metadata": {},
   "source": [
    "# Model Training and Feature Importance Analysis\n",
    "\n",
    "This notebook trains a Random Forest model on the processed molecular data and analyzes which features are most important for predicting flashpoint values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8171598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (11756, 15)\n",
      "Test data shape: (2940, 15)\n",
      "Features: ['is_silicon', 'is_metallic', 'is_tin', 'is_acid', 'MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'NumRotatableBonds', 'NumAromaticRings', 'TPSA', 'data_type_randonly selected as training point or test point', 'data_type_test data', 'data_type_training data', 'source_encoded']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load processed data\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").squeeze()\n",
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\").squeeze()\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Features: {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87921201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Regressor...\n",
      "Model training completed!\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "print(\"Training Random Forest Regressor...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,          \n",
    "    max_depth=15,              \n",
    "    min_samples_split=5,        \n",
    "    min_samples_leaf=2,         \n",
    "    random_state=42,\n",
    "    n_jobs=-1                   \n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435aef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Performance:\n",
      "  RMSE: 17.1081\n",
      "  MAE:  9.5435\n",
      "  R²:   0.9434\n",
      "\n",
      "Test Set Performance:\n",
      "  RMSE: 28.9949\n",
      "  MAE:  15.9884\n",
      "  R²:   0.8415\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Training R²: 0.9434\n",
      "  Test R²:     0.8415\n",
      "  Difference:  0.1019\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "# Evaluate on both training and test sets\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, \"Training Set\")\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, \"Test Set\")\n",
    "\n",
    "# Calculate overfitting indicator\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(f\"  Training R²: {train_metrics['R2']:.4f}\")\n",
    "print(f\"  Test R²:     {test_metrics['R2']:.4f}\")\n",
    "print(f\"  Difference:  {train_metrics['R2'] - test_metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a94f4",
   "metadata": {},
   "source": [
    "**Overall** the model performs well. The difference of R² (accuracy-like metric) between the training set predictions and test set predictions is relatively low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0c2af",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for predicting flashpoint values using both built-in Random Forest feature importance and permutation importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis - Method 1: Built-in Random Forest Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features (Random Forest Built-in):\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409dcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis - Method 2: Permutation Importance\n",
    "print(\"Calculating permutation importance (this may take a few minutes)...\")\n",
    "perm_importance = permutation_importance(\n",
    "    rf_model, X_test, y_test, \n",
    "    n_repeats=10, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create dataframe for permutation importance\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance_mean': perm_importance.importances_mean,\n",
    "    'importance_std': perm_importance.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features (Permutation Importance):\")\n",
    "print(perm_importance_df.head(15))\n",
    "\n",
    "# Plot permutation importance with error bars\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_perm_features = perm_importance_df.head(15)\n",
    "plt.barh(range(len(top_perm_features)), top_perm_features['importance_mean'],\n",
    "         xerr=top_perm_features['importance_std'])\n",
    "plt.yticks(range(len(top_perm_features)), top_perm_features['feature'])\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Top 15 Feature Importances (Permutation)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection Based on Importance Thresholds\n",
    "def select_features_by_importance(importance_df, threshold=0.01):\n",
    "    \"\"\"Select features above a certain importance threshold\"\"\"\n",
    "    selected_features = importance_df[importance_df['importance'] >= threshold]['feature'].tolist()\n",
    "    return selected_features\n",
    "\n",
    "# Define importance thresholds\n",
    "rf_threshold = 0.01  # Features must have at least 1% importance\n",
    "perm_threshold = 0.001  # Permutation importance threshold\n",
    "\n",
    "# Select features using Random Forest importance\n",
    "rf_selected = select_features_by_importance(feature_importance, rf_threshold)\n",
    "print(f\"Features selected by Random Forest importance (>= {rf_threshold}): {len(rf_selected)}\")\n",
    "print(f\"Selected features: {rf_selected}\")\n",
    "\n",
    "# Select features using Permutation importance\n",
    "perm_selected = perm_importance_df[perm_importance_df['importance_mean'] >= perm_threshold]['feature'].tolist()\n",
    "print(f\"\\nFeatures selected by Permutation importance (>= {perm_threshold}): {len(perm_selected)}\")\n",
    "print(f\"Selected features: {perm_selected}\")\n",
    "\n",
    "# Find common important features between both methods\n",
    "common_features = list(set(rf_selected) & set(perm_selected))\n",
    "print(f\"\\nCommon important features between both methods: {len(common_features)}\")\n",
    "print(f\"Common features: {common_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training set predictions\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.5)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Flashpoint')\n",
    "plt.ylabel('Predicted Flashpoint')\n",
    "plt.title(f'Training Set Predictions\\nR² = {train_metrics[\"R2\"]:.4f}')\n",
    "\n",
    "# Test set predictions\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Flashpoint')\n",
    "plt.ylabel('Predicted Flashpoint')\n",
    "plt.title(f'Test Set Predictions\\nR² = {test_metrics[\"R2\"]:.4f}')\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(1, 3, 3)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Flashpoint')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot (Test Set)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a reduced model using only the most important features\n",
    "print(\"Training a reduced model using only the most important features...\")\n",
    "\n",
    "# Use the top 10 features from Random Forest importance\n",
    "top_features_rf = feature_importance.head(10)['feature'].tolist()\n",
    "X_train_reduced = X_train[top_features_rf]\n",
    "X_test_reduced = X_test[top_features_rf]\n",
    "\n",
    "# Train reduced model\n",
    "rf_reduced = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions with reduced model\n",
    "y_train_pred_reduced = rf_reduced.predict(X_train_reduced)\n",
    "y_test_pred_reduced = rf_reduced.predict(X_test_reduced)\n",
    "\n",
    "# Evaluate reduced model\n",
    "print(\"\\n=== REDUCED MODEL PERFORMANCE (Top 10 Features) ===\")\n",
    "train_metrics_reduced = evaluate_model(y_train, y_train_pred_reduced, \"Training Set (Reduced)\")\n",
    "test_metrics_reduced = evaluate_model(y_test, y_test_pred_reduced, \"Test Set (Reduced)\")\n",
    "\n",
    "# Compare with full model\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(f\"Full Model Test R²:    {test_metrics['R2']:.4f}\")\n",
    "print(f\"Reduced Model Test R²: {test_metrics_reduced['R2']:.4f}\")\n",
    "print(f\"Performance difference: {test_metrics_reduced['R2'] - test_metrics['R2']:.4f}\")\n",
    "print(f\"Features reduced from {X_train.shape[1]} to {len(top_features_rf)} ({(1-len(top_features_rf)/X_train.shape[1])*100:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features by importance levels\n",
    "def categorize_features_by_importance(feature_importance_df, high_thresh=0.05, medium_thresh=0.01):\n",
    "    \"\"\"Categorize features into high, medium, and low importance\"\"\"\n",
    "    high_importance = feature_importance_df[feature_importance_df['importance'] >= high_thresh]['feature'].tolist()\n",
    "    medium_importance = feature_importance_df[\n",
    "        (feature_importance_df['importance'] >= medium_thresh) & \n",
    "        (feature_importance_df['importance'] < high_thresh)\n",
    "    ]['feature'].tolist()\n",
    "    low_importance = feature_importance_df[feature_importance_df['importance'] < medium_thresh]['feature'].tolist()\n",
    "    \n",
    "    return high_importance, medium_importance, low_importance\n",
    "\n",
    "# Categorize features\n",
    "high_imp, medium_imp, low_imp = categorize_features_by_importance(feature_importance)\n",
    "\n",
    "print(\"=== FEATURE IMPORTANCE CATEGORIZATION ===\")\n",
    "print(f\"\\nHIGH IMPORTANCE FEATURES (>= 5%): {len(high_imp)}\")\n",
    "for i, feature in enumerate(high_imp, 1):\n",
    "    importance_value = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "    print(f\"  {i}. {feature}: {importance_value:.4f}\")\n",
    "\n",
    "print(f\"\\nMEDIUM IMPORTANCE FEATURES (1% - 5%): {len(medium_imp)}\")\n",
    "for i, feature in enumerate(medium_imp, 1):\n",
    "    importance_value = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "    print(f\"  {i}. {feature}: {importance_value:.4f}\")\n",
    "\n",
    "print(f\"\\nLOW IMPORTANCE FEATURES (< 1%): {len(low_imp)}\")\n",
    "print(f\"  Features: {low_imp[:10]}...\")  # Show first 10 low importance features\n",
    "print(f\"  (and {max(0, len(low_imp)-10)} more)\")\n",
    "\n",
    "# Save feature importance results\n",
    "feature_importance.to_csv(\"../data/processed/feature_importance.csv\", index=False)\n",
    "print(f\"\\n✅ Feature importance results saved to ../data/processed/feature_importance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
